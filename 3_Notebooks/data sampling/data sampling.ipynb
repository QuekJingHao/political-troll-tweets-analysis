{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c3ca604f-4830-4202-ae1b-d5d111a228a6",
   "metadata": {},
   "source": [
    "# Political Troll Tweets Analysis: Data Sampling\n",
    "---\n",
    "\n",
    "**<u>_Objective:_</u>** In this project, we perform exploratory data analysis on Russian, Chinese and Indonesian information operations, to uncover the trolls' tradecraft and modus operandi against a target populace.\n",
    "\n",
    "This notebook performs data sampling on the raw datasets, to obtain a dataset to be used in the project\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2864f181-18ec-4276-88c8-d7c1a027d652",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "d413cffa-569d-4878-ac81-8d13ce32b083",
   "metadata": {},
   "source": [
    "#### Data Collection\n",
    "Do only this part for the data collection and aggregation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9d9c13a1-5bc0-496a-858c-c61db1d39dc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import modules and dependencies\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import shutil as sh\n",
    "\n",
    "from data_collection_utility import *\n",
    "\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "pd.set_option('display.max_columns', None)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b5d5164-72e8-4278-a24b-9ec7fecadc8a",
   "metadata": {},
   "source": [
    "### Russia\n",
    "\n",
    "Remember to rerun this cell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e7cefc4c-bd3f-4286-98f3-1b7187437775",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "G:\\My Drive\\State-linked Information Ops Analysis\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "cur_dir = os.getcwd()\n",
    "print(cur_dir[:-24])\n",
    "\n",
    "#path = 'H:/My Drive/State-linked Information Ops Analysis/data/'\n",
    "path = 'C:/Users/jh.quek/Documents/SPOTTED Data Collection/data2/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "084a15e5-0351-4c16-ab49-0bb37c52d7a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "List of datasets for state actor Russia \n",
      " ['Russia_GRU_Feb_2021.csv', 'Russia_IRA_Feb_2021.csv', 'Russia_IRA_Oct_2018.csv', 'Russia_Jan_2019.csv', 'Russia_May_2020.csv']\n",
      "Length of Russia_GRU_Feb_2021.csv dataframe is 26684\n",
      "Length of Russia_IRA_Feb_2021.csv dataframe is 68914\n",
      "Length of Russia_IRA_Oct_2018.csv dataframe is 8768633\n",
      "Length of Russia_Jan_2019.csv dataframe is 920761\n",
      "Length of Russia_May_2020.csv dataframe is 3434792\n",
      "Length of merged dataframe is 13219784, [True]\n",
      "[*]--------------------------------------      SUCCESS      --------------------------------------[*]\n",
      "\n",
      "Writing to csv file ...\n",
      "[*]----------------------------------------------- Complete -----------------------------------------------[*]\n",
      "\n",
      "List of datasets for state actor China \n",
      " ['China_Changyu_Culture_Dec_2021.csv', 'China_May_2020.csv', 'China_S1_Aug_2019.csv', 'China_S2_Aug_2019.csv', 'China_S3_Sept_2019.csv', 'China_Xinjiang_Dec_2021.csv']\n",
      "Length of China_Changyu_Culture_Dec_2021.csv dataframe is 35924\n",
      "Length of China_May_2020.csv dataframe is 348608\n",
      "Length of China_S1_Aug_2019.csv dataframe is 1898108\n",
      "Length of China_S2_Aug_2019.csv dataframe is 1708078\n",
      "Length of China_S3_Sept_2019.csv dataframe is 10241545\n",
      "Length of China_Xinjiang_Dec_2021.csv dataframe is 31269\n",
      "Length of merged dataframe is 14263532, [True]\n",
      "[*]--------------------------------------      SUCCESS      --------------------------------------[*]\n",
      "\n",
      "Writing to csv file ...\n",
      "[*]----------------------------------------------- Complete -----------------------------------------------[*]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "state_actors = ['Russia', 'China']\n",
    "\n",
    "for state_actor in state_actors:\n",
    "    \n",
    "    datasets = os.listdir(path + state_actor)\n",
    "    print('List of datasets for state actor', state_actor, '\\n', datasets)\n",
    "    combined_df = dataset_fusion(path + state_actor + '/',  datasets)\n",
    "\n",
    "    # pick half a random sample of the total dataframe with only English tweets\n",
    "    combined_sample_df = combined_df[combined_df['tweet_language'] == 'en']\n",
    "    combined_sample_df = combined_sample_df.sample(frac = 0.5, random_state = 46)\n",
    "    \n",
    "    # do a random shuffle for the combined dataset\n",
    "    combined_sample_df = combined_sample_df.sample(frac = 1.0, random_state = 42)\n",
    "    \n",
    "    print('Writing to csv file ...')\n",
    "    combined_sample_df.to_csv(state_actor +  '_Sample.csv')\n",
    "    print('[*]----------------------------------------------- Complete -----------------------------------------------[*]\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9d3dfb1-59d6-458b-a423-c2fb5999caaf",
   "metadata": {
    "tags": []
   },
   "source": [
    "### China\n",
    "\n",
    "For China, we only pick two folders:\n",
    "- China Changyu Culture\n",
    "- China XinJiang"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "063e1fc9-be44-4d67-ba5b-77989e2e458e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['G:\\\\My Drive\\\\State-linked Information Ops Analysis\\\\data\\\\China Changyu Culture\\\\CNCC_0621_tweets_csv_hashed_2012.csv',\n",
       " 'G:\\\\My Drive\\\\State-linked Information Ops Analysis\\\\data\\\\China Changyu Culture\\\\CNCC_0621_tweets_csv_hashed_2013.csv',\n",
       " 'G:\\\\My Drive\\\\State-linked Information Ops Analysis\\\\data\\\\China Changyu Culture\\\\CNCC_0621_tweets_csv_hashed_2014.csv',\n",
       " 'G:\\\\My Drive\\\\State-linked Information Ops Analysis\\\\data\\\\China Changyu Culture\\\\CNCC_0621_tweets_csv_hashed_2015.csv',\n",
       " 'G:\\\\My Drive\\\\State-linked Information Ops Analysis\\\\data\\\\China Changyu Culture\\\\CNCC_0621_tweets_csv_hashed_2016.csv',\n",
       " 'G:\\\\My Drive\\\\State-linked Information Ops Analysis\\\\data\\\\China Changyu Culture\\\\CNCC_0621_tweets_csv_hashed_2017.csv',\n",
       " 'G:\\\\My Drive\\\\State-linked Information Ops Analysis\\\\data\\\\China Changyu Culture\\\\CNCC_0621_tweets_csv_hashed_2018.csv',\n",
       " 'G:\\\\My Drive\\\\State-linked Information Ops Analysis\\\\data\\\\China Changyu Culture\\\\CNCC_0621_tweets_csv_hashed_2019.csv',\n",
       " 'G:\\\\My Drive\\\\State-linked Information Ops Analysis\\\\data\\\\China Changyu Culture\\\\CNCC_0621_tweets_csv_hashed_2020.csv',\n",
       " 'G:\\\\My Drive\\\\State-linked Information Ops Analysis\\\\data\\\\China Changyu Culture\\\\CNCC_0621_tweets_csv_hashed_2021.csv']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "os.listdir(cur_dir[:-24] + '\\\\data\\\\China Changyu Culture')\n",
    "\n",
    "full_path = [os.path.join(cur_dir[:-24] + '\\\\data\\\\China Changyu Culture', file) for file in os.listdir(cur_dir[:-24] + '\\\\data\\\\China Changyu Culture')]\n",
    "full_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "02611041-b8a8-4a68-9fa3-5b83f97cf510",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['CNCC_0621_tweets_csv_hashed_2012.csv',\n",
       " 'CNCC_0621_tweets_csv_hashed_2013.csv',\n",
       " 'CNCC_0621_tweets_csv_hashed_2014.csv',\n",
       " 'CNCC_0621_tweets_csv_hashed_2015.csv',\n",
       " 'CNCC_0621_tweets_csv_hashed_2016.csv',\n",
       " 'CNCC_0621_tweets_csv_hashed_2017.csv',\n",
       " 'CNCC_0621_tweets_csv_hashed_2018.csv',\n",
       " 'CNCC_0621_tweets_csv_hashed_2019.csv',\n",
       " 'CNCC_0621_tweets_csv_hashed_2020.csv',\n",
       " 'CNCC_0621_tweets_csv_hashed_2021.csv']"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.listdir(cur_dir[:-24] + '\\\\data\\\\China Changyu Culture')\n",
    "#China_Changyu_Culture_df = [pd.read_csv(file) for file in os.listdir(cur_dir[:-24] + '\\\\data\\\\China Changyu Culture')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f47959d5-b581-4b55-81f2-3c2ae28f71da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing to csv file ...\n",
      "[*]----------------------------------------------- Complete -----------------------------------------------[*]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "China_CC_path = cur_dir[:-24] + '\\\\data\\\\China Changyu Culture'\n",
    "China_XJ_path = cur_dir[:-24] + '\\\\data\\\\China Xinjiang'\n",
    "\n",
    "China_CC_full_path = [os.path.join(China_CC_path, file) for file in os.listdir(China_CC_path)]\n",
    "China_XJ_full_path = [os.path.join(China_XJ_path, file) for file in os.listdir(China_XJ_path)]\n",
    "\n",
    "China_Changyu_Culture_df = [pd.read_csv(file) for file in China_CC_full_path]\n",
    "China_XinJiang_df = [pd.read_csv(file) for file in China_XJ_full_path]\n",
    "\n",
    "\n",
    "China_df = China_Changyu_Culture_df + China_XinJiang_df\n",
    "\n",
    "# concatenate the dataframe\n",
    "combined_df = pd.concat(China_df)\n",
    "\n",
    "\n",
    "# pick half a random sample of the total dataframe with only English tweets\n",
    "combined_sample_df = combined_df[combined_df['tweet_language'] == 'en']\n",
    "#combined_sample_df = combined_sample_df.sample(frac = 0.5, random_state = 46)\n",
    "\n",
    "# do a random shuffle for the combined dataset\n",
    "combined_sample_df = combined_sample_df.sample(frac = 1.0, random_state = 42)\n",
    "\n",
    "print('Writing to csv file ...')\n",
    "combined_sample_df.to_csv('China_CCXJ' +  '_Sample.csv')\n",
    "print('[*]----------------------------------------------- Complete -----------------------------------------------[*]\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6337213a-8601-4096-bba3-959e5182bd72",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef7147bc-ca4b-4705-a751-20e201828e87",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
